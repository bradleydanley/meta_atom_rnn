## Purpose: Configuration File
# Author: Andy

# System parameter - We can either run locally (out of a docker image) or on kubernetes
# If deployment_mode = 0, we are running locally.
# If deployment_mode = 1, we are using kubernetes / the nautilus cluster

deployment_mode: 1

# If we're local but automating via bash, we need a flag for main.py
# If bash = 1, we are automating locally. This only applies to training (experiment=1)

bash : 0

# Expriment Parameter
# - 0 = preprocess data (from reduced volumes to y component of 1550 slices plus phases)
# - 1 = train network
# - 2 = load results
# - 3 = run evaluation

experiment: 1 # setting this to 1?? Don't forget to set bash to 1 if you're using ./train.sh!! 

# Path Parameters - used for running 'locally' - but within a docker container, not kubernetes
# - paths are mounted as /develop/data, /develop/code, /develop/results
# - data: path to dataset folder
# - results: path to results folder

mounted_paths:
  data:
    volumes: /develop/data/meep-dataset-v2/volumes
    preprocessed_data: /develop/data/meep-dataset-v2/preprocessed_data
    train: /develop/data/meep-dataset-v2/preprocessed_data/train
    valid: /develop/data/meep-dataset-v2/preprocessed_data/valid
  results:
    checkpoints: /develop/results/meta_atom_rnn/checkpoints
    analysis: /develop/results/meta_atom_rnn/analysis
  code:
    params: /develop/code/meta_atom_rnn/configs/params.yaml
    library : /develop/code/meta_atom_rnn/utils/neighbors_library_allrandom.pkl  
 

# System Parameters for NN training
# - num_workers: number of cpus for data loader
# - strategy: lightning trainer configuration
# - num_devices: number of acceleration devices
# - accelerator: type of acceleration device (i.e., cpu, cuda, mps)

system:
  num_workers: 3
  gpus: 
    strategy : auto
    num_devices : 1
    accelerator : cuda 

# Dataset Parameters
# - seq_len: number of sequential slices per sample

dataset:
  seq_len:  
  vmin_real:
  vmax_imag:

# General Network Parameters
# - arch: network architecture (0 = rnn, 1 = lstm, 2 = convlstm)
# - batch_size: number of samples for one network observation
# - num_epochs: number of times algorithm observes entire train dataset
# - learning_rate: step size of gradient descent optimization
# - scheduler: defines scheduler use (0=scheduler on, 1=scheduler off)
network:
  arch:  
  batch_size: 24
  num_epochs: 50
  learning_rate: 0.01
  scheduler: 0

# RNN / LSTM Parameters
# - num_layers: number of rnn / lstm layers (i.e., stacked networks)
# - i_dims: number of input dimensions for rnn / lstm
# - h_dims: number of hidden dimensions for rnn / lstm

rnn_lstm:
  num_layers: 5
  i_dims: 55112
  h_dims: 256

# ConvLSTM Parameters
# - in_channels: in channels of convolution for convlstm
# - kernel_size: kernel size of convolution for convlstm
# - padding: padding size of convolution for convlstm

convlstm:
  num_layers: 1
  in_channels: 2
  out_channels: 2
  kernel_size: 3
  padding: 1
  spatial: 166


# Visualization Parameters for evaluation/analysis
#  We also end up recycling visualize.sequences to automate experiments

visualize:
  all_versions: ['rnn', 'lstm']
  #all_versions: [0, 1]
  exclude_group: [epoch, step]
  #sequences : [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60]
  sequences: [5,10,15]
  domain : real

# Copies of parameters for automation - These are used as arguments to be passed at runtime
# and parsed. They are command-line arguments. Never set them here - they get changed as the
# experiment is run. Once these are set, network.arch and dataset.seq_len are updated.

arch: 
seq_len: 

# Kubernetes (k8s) parameters. 

kube :
  namespace : gpn-mizzou-muem
  image : docker.io/kovaleskilab/meep:v3_lightning
  job_files : /home/mindful/Documents/data/kube_jobs  # this is a local directory
  pvc_volumes : dft-volumes # use `kubectl get pvc` to see list of pvcs
  pvc_preprocessed : preprocessed-data 
  pvc_results : training-results

  pp_job:
    num_cpus : 4
    num_mem_lim : 150Gi 
    num_mem_req : 100Gi
    kill_tag : preprocess
    
    paths :

      # local / repo path where meta-atom radii are stored

      # interactive pod directories
      data :
        volumes : /develop/results  # points to folder containing reduced volumes in pvc called dft-volumes
        preprocessed_data : /develop/data/preprocessed_data # points to folder containing data after it has been preprocessed in pvc called preprocessed-data 
      timing : /develop/data/preprocessed_data/timing 

      # local path where template is located
      template : templates/preprocess_job.txt

  train_job :
    num_cpus : 1
    num_mem_lim : 64Gi
    num_mem_req : 64Gi
    num_gpus : 1
    kill_tags : [rnn,lstm]
    sequence :
    arch :
 
    paths :
      data :
        train : /develop/data/preprocessed_data/train
        valid : /develop/data/preprocessed_data/valid
      results :
        # interactive pod directories
        model_results : /develop/results
        model_checkpoints : /develop/results/checkpoints
        analysis : /develop/results/analysis
      logs : /develop/results/checkpoints/current_logs
      # local path where template is located
      template : templates/train_job.txt

  load_results_job :
    num_mem_req : 128Gi
    num_mem_lim : 128Gi
    paths :
      template : templates/load_results_job.txt
      params: /develop/code/meta_atom_rnn/configs/params.yaml
    kill_tag : load-results
    sequence : 

  evaluation_job :
    paths:
      template : templates/evaluation_job.txt
    kill_tag : evaluation           
